# Load necessary libraries for the analysis
library(AutoScore)
library(dplyr)
library(corrplot)
library(openxlsx)
library(caret)
library(pROC)
library(ggplot2)
library(svglite)
library(grDevices)

# Set the working directory where the data and output files are located
setwd("C:/Users/11373/Desktop/Auto score")

# Load the dataset from a CSV file
sample_data <- read.csv("C:/Users/11373/Desktop/Auto score/AIBL_by_id.csv")

# Rename the column "Neuropsych.Simple.Classification" to "label"
names(sample_data)[names(sample_data) == "Neuropsych.Simple.Classification"] <- "label"

# Subset the data to exclude rows where the label is "MCI"
sample_data <- subset(sample_data, sample_data$label != "MCI")

# Recode the labels: "HC" and "MCI" as 0 (healthy control), "AD" as 1 (Alzheimer's disease)
sample_data$label[sample_data$label == "HC"] <- 0
sample_data$label[sample_data$label == "MCI"] <- 0
sample_data$label[sample_data$label == "AD"] <- 1

# Group the data by participant ID and select the last row for each participant
sample_data <- sample_data %>%
  group_by(AIBL.Id) %>%
  filter(row_number() == n())

# Define a function to identify if a column is categorical (character or factor)
is_categorical <- function(column) {
  is.character(column) || is.factor(column)
}

# Identify the categorical columns in the dataset
categorical_columns <- sapply(sample_data, is_categorical)

# Replace "NI" with NA only in the categorical columns
sample_data <- sample_data %>%
  ungroup() %>%  # Remove grouping
  mutate(across(where(is_categorical), ~ifelse(. == "NI", NA, .)))

# Remove rows with NA values from the dataset
sample_data <- na.omit(sample_data)

# Identify columns that are of character type
char_cols <- sapply(sample_data, is.character)

# Convert character columns to factors
sample_data[char_cols] <- lapply(sample_data[char_cols], as.factor)

# Display the dimensions of the cleaned dataset
dim(sample_data)

# Check the data to ensure it meets the requirements for AutoScore
check_data(sample_data)

# Step 2: Extract unique participant IDs
participant_ids <- unique(sample_data$AIBL.Id)

# Step 3: Shuffle the participant IDs randomly for splitting into train, validation, and test sets
set.seed(123) # Set seed for reproducibility
shuffled_ids <- sample(participant_ids)

# Step 4: Calculate the number of participants for the training, validation, and test sets
total_participants <- length(shuffled_ids)
train_size <- round(0.7 * total_participants)
val_size <- round(0 * total_participants)
test_size <- total_participants - train_size - val_size

# Step 5: Assign participants to the training, validation, and test sets
train_ids <- shuffled_ids[1:train_size]
val_ids <- shuffled_ids[(train_size + 1):(train_size + val_size)]
test_ids <- shuffled_ids[(train_size + val_size + 1):total_participants]

# Step 6: Subset the data based on the assigned participant IDs
train_set <- sample_data[sample_data$AIBL.Id %in% train_ids, ]
validation_set <- train_set # Use training set as validation set
test_set <- sample_data[sample_data$AIBL.Id %in% test_ids, ]

# Remove the first column (participant ID) from the training data
train_set <- train_set[, -c(1)]
# Remove the first column (participant ID) from the validation data
validation_set <- validation_set[, -c(1)]
# Remove the first column (participant ID) from the test data
test_set <- test_set[, -c(1)]

###############################################################

# Save a plot of the feature ranking generated by AutoScore using Random Forest (RF) method
jpeg(filename = "AutoScore_rank_plot1.jpg", width = 12, height = 7, units = "in", res = 800)
ranking <- AutoScore_rank(train_set = train_set, method = "rf", ntree = 200)
dev.off()

# Extract the names of the top-ranked features
nam <- names(ranking)

# Select the top 35 features based on ranking and append the label column
train_set1 <- cbind(train_set[, names(ranking[1:35])])
train_set1$label <- train_set$label
train_set <- train_set1
validation_set1 <- cbind(validation_set[, names(ranking[1:35])])
validation_set1$label <- validation_set$label
validation_set <- validation_set1
test_set1 <- cbind(test_set[, names(ranking[1:35])])
test_set1$label <- test_set$label
test_set <- test_set1

# Save a plot of the AUC performance generated by AutoScore's parsimony step
jpeg(filename = "AutoScore_AUC_plot1.jpg", width = 12, height = 7, units = "in", res = 800)
AUC <- AutoScore_parsimony(
  train_set = train_set, validation_set = validation_set, 
  rank = ranking, max_score = 100, n_min = 1, n_max = 35,
  categorize = "quantile", quantiles = c(0, 0.25, 0.5, 0.75, 1), 
  auc_lim_min = 0.5, auc_lim_max = "adaptive",
  cross_validation = TRUE, fold = 10, do_trace = FALSE
)
dev.off()

# Select the number of variables to include in the final model
num_var <- 11

# Extract the names of the top 'num_var' variables
final_variables <- names(ranking[c(1:num_var)])

# Perform the weighting step of AutoScore for the selected variables
cut_vec <- AutoScore_weighting( 
  train_set = train_set, validation_set = validation_set,
  final_variables = final_variables, max_score = 100,
  categorize = "quantile", quantiles = c(0, 0.25, 0.5, 0.75, 1), metrics_ci = TRUE
)

# Manually fine-tune the selected factors' thresholds for better performance
cut_vec$GDS <- c(5, 10)
cut_vec$Blood.pressure.diastolic. <- c(60, 80, 90)
cut_vec$Blood.pressure.systolic. <- c(120, 150)

# Perform fine-tuning of the scoring system using the refined thresholds
scoring_table <- AutoScore_fine_tuning(
  train_set = train_set, validation_set = validation_set, 
  final_variables = final_variables, cut_vec = cut_vec, max_score = 100, metrics_ci = TRUE
)

# Save a plot of the ROC curve generated by AutoScore's testing step
png(filename = "auc3.png", width = 10, height = 10, units = "in", res = 800)
pred_score <- AutoScore_testing(
  test_set = test_set, final_variables = final_variables, cut_vec = cut_vec,
  scoring_table = scoring_table, threshold = "best", with_label = TRUE
)
dev.off()

# Add the predicted scores to the test set data
test_set$pred <- pred_score$pred_score

# Save the test set with predictions to a CSV file
write.csv(test_set, "test_set.csv", row.names = FALSE)

# Generate conversion tables based on predicted scores to risk levels
conversion_table(pred_score = pred_score, 
                 by = "risk", values = c(0.15, 0.25, 0.5, 0.6, 0.75))

# Generate conversion tables based on predicted scores to score levels
conversion_table(pred_score = pred_score, 
                 by = "score", values = c(20, 40, 55, 65))

# Load additional libraries for plotting and exporting data
library(ggplot2)
library(plotly)
library(openxlsx)

# Fit a logistic regression model to the predicted scores and labels
glmmodel <- glm(Label ~ pred_score, data = pred_score, family = binomial(link = "logit"))

# Predict risk scores using the fitted logistic model
pred_risk <- predict(glmmodel, newdata = pred_score, type = "response")

# Create a sequence of predicted scores ranging from 1 to 100
pred_score <- 0:100

# Create a label column with all values set to 1
Label <- rep(1, 101)

# Combine the predicted scores and labels into a dataframe
data <- data.frame(pred_score, Label)

# Predict risk scores for the new data based on the fitted model
pred_risk1 <- predict(glmmodel, newdata = data, type = "response")

# Add the predicted risk scores to the data
data$risk <- pred_risk1

# Create a ggplot object for the risk plot
scatter_plot <- ggplot(data, aes(x = pred_score, y = pred_risk1)) +
  geom_point() + geom_line() +  # Add points and a line
  labs(x = "Score", y = "Risk", title = "Risk Plot")  # Add axis labels and title

# Save the plot as a PNG image
png(filename = "scatter_plot.png", width = 15, height = 10, units = "in", res = 800)

# Convert the ggplot object to an interactive plotly object
scatter_plot <- ggplotly(scatter_plot, tooltip = c("x", "y"))

# Print the interactive plot (for visualization, though not necessary for saving)
scatter_plot
dev.off()

# Save the data containing predicted risks and scores to an Excel file
write.xlsx(data, "Risk_Data.xlsx")
